{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroconcejero/deep_learning_CNN/blob/main/Paquita_Salas_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yAQ4EFQn66Q"
      },
      "source": [
        "**Importación de Librerias**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lPpBIgIAAIxp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ifaDLnBICO",
        "outputId": "aedfcc3c-9924-45ce-d410-107fb47b4ccd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_04tdU-oCRj"
      },
      "source": [
        "**Descarga y preprocesado de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u75nLCa-AW7m",
        "outputId": "80e606fd-6fd7-48c1-ec36-e5b9cc0c8586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del texto:        84996 carácteres\n",
            "El texto está compuesto de estos 100 carácteres:\n",
            "['\\n', '\\r', ' ', '!', '#', '%', '&', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', ':', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '´', '¿', 'Á', 'É', 'Í', 'Ñ', 'Ó', 'Ú', 'Ü', 'á', 'ç', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '’', '“', '”', '…', '\\ufeff']\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "text = open(\"/content/gdrive/MyDrive/Colab Notebooks/Paquita_Salas.txt\", 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:        {} carácteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "print ('El texto está compuesto de estos {} carácteres:'.format(len(vocab)))\n",
        "print (vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ItsMgJVBMC3",
        "outputId": "aa83e5c6-e7fb-4b5b-e976-dfd6838f6792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  '\\n':   0,\n",
            "  '\\r':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '#' :   4,\n",
            "  '%' :   5,\n",
            "  '&' :   6,\n",
            "  '(' :   7,\n",
            "  ')' :   8,\n",
            "  ',' :   9,\n",
            "  '-' :  10,\n",
            "  '.' :  11,\n",
            "  '/' :  12,\n",
            "  '0' :  13,\n",
            "  '1' :  14,\n",
            "  '2' :  15,\n",
            "  '3' :  16,\n",
            "  '4' :  17,\n",
            "  '5' :  18,\n",
            "  '6' :  19,\n",
            "  '7' :  20,\n",
            "  ':' :  21,\n",
            "  '?' :  22,\n",
            "  '@' :  23,\n",
            "  'A' :  24,\n",
            "  'B' :  25,\n",
            "  'C' :  26,\n",
            "  'D' :  27,\n",
            "  'E' :  28,\n",
            "  'F' :  29,\n",
            "  'G' :  30,\n",
            "  'H' :  31,\n",
            "  'I' :  32,\n",
            "  'J' :  33,\n",
            "  'K' :  34,\n",
            "  'L' :  35,\n",
            "  'M' :  36,\n",
            "  'N' :  37,\n",
            "  'O' :  38,\n",
            "  'P' :  39,\n",
            "  'Q' :  40,\n",
            "  'R' :  41,\n",
            "  'S' :  42,\n",
            "  'T' :  43,\n",
            "  'U' :  44,\n",
            "  'V' :  45,\n",
            "  'W' :  46,\n",
            "  'X' :  47,\n",
            "  'Y' :  48,\n",
            "  'Z' :  49,\n",
            "  '_' :  50,\n",
            "  'a' :  51,\n",
            "  'b' :  52,\n",
            "  'c' :  53,\n",
            "  'd' :  54,\n",
            "  'e' :  55,\n",
            "  'f' :  56,\n",
            "  'g' :  57,\n",
            "  'h' :  58,\n",
            "  'i' :  59,\n",
            "  'j' :  60,\n",
            "  'k' :  61,\n",
            "  'l' :  62,\n",
            "  'm' :  63,\n",
            "  'n' :  64,\n",
            "  'o' :  65,\n",
            "  'p' :  66,\n",
            "  'q' :  67,\n",
            "  'r' :  68,\n",
            "  's' :  69,\n",
            "  't' :  70,\n",
            "  'u' :  71,\n",
            "  'v' :  72,\n",
            "  'w' :  73,\n",
            "  'x' :  74,\n",
            "  'y' :  75,\n",
            "  'z' :  76,\n",
            "  '¡' :  77,\n",
            "  '´' :  78,\n",
            "  '¿' :  79,\n",
            "  'Á' :  80,\n",
            "  'É' :  81,\n",
            "  'Í' :  82,\n",
            "  'Ñ' :  83,\n",
            "  'Ó' :  84,\n",
            "  'Ú' :  85,\n",
            "  'Ü' :  86,\n",
            "  'á' :  87,\n",
            "  'ç' :  88,\n",
            "  'é' :  89,\n",
            "  'í' :  90,\n",
            "  'ñ' :  91,\n",
            "  'ó' :  92,\n",
            "  'ú' :  93,\n",
            "  'ü' :  94,\n",
            "  '’' :  95,\n",
            "  '“' :  96,\n",
            "  '”' :  97,\n",
            "  '…' :  98,\n",
            "  '\\ufeff':  99,\n"
          ]
        }
      ],
      "source": [
        "#Como las redes neuronales solo procesan valores numéricos, no letras. Traduciremos los caracteres a representación numérica.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e-7yufZABUlU"
      },
      "outputs": [],
      "source": [
        "#Ahora pasaremos el texto a un array de enteros\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wq-zN5kBVKK",
        "outputId": "7dda0944-486c-48e5-dee3-e27580d8d7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto : '\\ufeffPAQUITA:\\r\\nHola, soy Paquita Salas y soy represent'\n",
            "array([99, 39, 24, 40, 44, 32, 43, 24, 21,  1,  0, 31, 65, 62, 51,  9,  2,\n",
            "       69, 65, 75,  2, 39, 51, 67, 71, 59, 70, 51,  2, 42, 51, 62, 51, 69,\n",
            "        2, 75,  2, 69, 65, 75,  2, 68, 55, 66, 68, 55, 69, 55, 64, 70])\n"
          ]
        }
      ],
      "source": [
        "#Mostramos los 50 primeros caracteres del texto text_as_init\n",
        "print ('texto : {}'.format(repr(text[:50])))\n",
        "print ('{}'.format(repr(text_as_int[:50])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiEo1IbooZT9"
      },
      "source": [
        "**Preparación de los datos para entrenar la RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s5q3NUFIBVOt"
      },
      "outputs": [],
      "source": [
        "#Para entrenar el modelo creamos un conjunto de datos con el contenido de text_as_init. Para ello utilizamos la función tf.data.Dataset.from_tensor_slices.\n",
        "#A este conjunto de datos lo dividiremos en secuencias de seq_length+1 al aplicar el método batch()\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "seq_length = 100\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_04GR_o-BVVb",
        "outputId": "0aa79134-c78b-45c8-89ae-13d76a73b170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\ufeffPAQUITA:\\r\\nHola, soy Paquita Salas y soy representante.\\r\\n\\r\\n\\r\\nPAQUITA SALAS habla acaloradamente por t'\n",
            "'eléfono. \\r\\n\\r\\n\\r\\nUn cuadro gigante de MACARENA GARCÍA, su actriz más importante, corona la sala. Al lad'\n",
            "'o del cuadro, una estantería gigante llena de videobooks de actores. \\r\\n\\r\\n\\r\\nPAQUITA: \\r\\n¡¡Pero el acent'\n",
            "'o colombiano, ella se trabaja el acento colombiano!! \\r\\n\\r\\n\\r\\nMAGÜI, una mujer de 30 años, andaluza, alt'\n",
            "'a y con el pelo corto, se acerca a ella temerosa. \\r\\n\\r\\n\\r\\nMAGÜI: \\r\\nPaquita… \\r\\n\\r\\n\\r\\nPAQUITA:\\r\\n¿Qué? \\r\\n\\r\\n\\r'\n",
            "'\\nMAGÜI: \\r\\nEstá aquí Lidia. \\r\\n\\r\\n\\r\\nLIDIA SAN JOSÉ, una actriz representada por PAQUITA, está en la puer'\n",
            "'ta de la oficina. Saluda, tímida. PAQUITA, al teléfono, le lanza un beso con la mano. \\r\\n\\r\\n\\r\\nPAQUITA ('\n",
            "'A MAGÜI):\\r\\nLo de Oysho está ahí. (Al teléfono) ¡¡Es actriz, ella se ha hecho cursos!! \\r\\n\\r\\n\\r\\nMAGÜI cog'\n",
            "'e una bolsa y se la da a LIDIA, que le da las gracias. LIDIA saca de la bolsa un camisón. PAQUITA cue'\n",
            "'lga. \\r\\n\\r\\n\\r\\nPAQUITA: \\r\\nMagüi, ¿ha llamado Macarena? \\r\\n\\r\\n\\r\\nMAGÜI: \\r\\nNo. \\r\\n\\r\\n\\r\\nPAQUITA (A LIDIA, señalan'\n"
          ]
        }
      ],
      "source": [
        "#Comprobamos que las sequences son el texto dividido en 101 caracteres (mostramos 10 secuencias)\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5k9qphFpB5ws"
      },
      "outputs": [],
      "source": [
        "#Creamos una función que devolverá el conjunto de datos de entrenamiento (los datos de entrada como los datos de salida)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#Aplicamos la función a todas las secuencias utilizando el método map()\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfs-DM9XB56u",
        "outputId": "3535857d-a1dd-4d8d-bc58-60418fff85f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  '\\ufeffPAQUITA:\\r\\nHola, soy Paquita Salas y soy representante.\\r\\n\\r\\n\\r\\nPAQUITA SALAS habla acaloradamente por '\n",
            "Target data: 'PAQUITA:\\r\\nHola, soy Paquita Salas y soy representante.\\r\\n\\r\\n\\r\\nPAQUITA SALAS habla acaloradamente por t'\n",
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "#Los dataset contienen un conjunto de parejas (100 caracteres del texto original, la correspondiente salida ). Vamos a mostrar la primera pareja.\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n",
        "\n",
        "  print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G69aZMOIB6AM",
        "outputId": "759431e5-de15-4e02-9386-d5de6fe6233e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "#Agrupamos los dataset en batches de 64 . Así tendriamos los datos de entrenamiento con batches compuestos de 64 parejas de secuencias de 100 integers de 64 bits\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print (dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv8SzZY9o-4G"
      },
      "source": [
        "**Construcción del modelo RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eB5oYVSUB6EZ"
      },
      "outputs": [],
      "source": [
        "#Crearemos una función que cree un modelo RNN con tres capas\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = Sequential()\n",
        "  #Añadimos la capa de tipo word embedding\n",
        "  model.add(Embedding(input_dim=vocab_size,\n",
        "                      output_dim=embedding_dim,\n",
        "                      #batch_input_shape=[batch_size, None] Deprecated\n",
        "                      ))\n",
        "  #Añadimos la capa de tipo LSTM\n",
        "  model.add(LSTM(rnn_units,\n",
        "                 return_sequences=True,\n",
        "                 stateful=True,\n",
        "                 recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(512, activation=\"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "  #Añadimos la capa de tipo Dense\n",
        "  model.add(Dense(vocab_size))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YdgPsCk2CUiA"
      },
      "outputs": [],
      "source": [
        "#Creamos el modelo\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "rl8nlYQsCUrn",
        "outputId": "d6ffebeb-d95d-405a-f9f0-6259920bb178"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-ZlHgoPCUwY",
        "outputId": "3f484f36-59ec-426e-c24c-08dd8c9e0605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: (64, 100) # (batch_size, sequence_length)\n",
            "Target: (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ],
      "source": [
        "#A continuación inspecionamos las dimenciones de los tensores\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
        "  print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjbTgZS2CUzO",
        "outputId": "d31f5337-d271-4a55-c35c-3633250e24d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction :  (64, 100, 100) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(\"Prediction : \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "y7gp_axeCpnI"
      },
      "outputs": [],
      "source": [
        "#Obtenemos una muestra de la distribución de salida\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L8mDKIdCpp_",
        "outputId": "bcc1d2ed-84cd-43fa-a481-a6fd085826fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[82 63 38 69  6 12 26 78 13 33 99 90 84 77 51 88 31 76 84 34 46 72  2 91\n",
            " 87 62 71  2 28 38 57 66 73 44 86  6 57 55 42  4 72 91 30 19 10  3 35 71\n",
            " 18 57 93 67 11 47 30 21 16 29 69 14 89 82 82 21 56 71 34  9 31 30 49 56\n",
            " 19 33 37 63  5 14 23 18 71 58 55 96 87 59 89 21 29 72 22 41 21 73 42 22\n",
            "  5 46 65 34]\n"
          ]
        }
      ],
      "source": [
        "print(sampled_indices_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJvq7sCMpNWS"
      },
      "source": [
        "**Entrenamiento del modelo RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uKqSJOP_Cpso"
      },
      "outputs": [],
      "source": [
        "#Creamos la función de perdida, usaremos el categorical pues estamos considerando datos categóricos\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YPNOYQq9Cpu-"
      },
      "outputs": [],
      "source": [
        "#Compilamos el modelo\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qqxhp8m-Cpw1"
      },
      "outputs": [],
      "source": [
        "#configuramos los checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints_Paquita'\n",
        "\n",
        "# nombre fichero\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROaEjLNDCuF",
        "outputId": "9980a17a-b276-4d67-934f-6529fbe5e6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 4.1522\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 3.3155\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 2.8902\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 2.5460\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 2.3300\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 2.2127\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 2.1022\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 2.0553\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 1.9936\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 1.9587\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 1.9030\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.8509\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 1.8205\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 1.7623\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 1.7296\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 1.7112\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 1.6486\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 1.6050\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.5848\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 1.5335\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 1.4942\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 1.4246\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 1.4426\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 1.3736\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 1.3269\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 1.2998\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 1.2508\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.1958\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 1.1639\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 1.1052\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 1.0731\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 1.0310\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 0.9858\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.9432\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.8952\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.8587\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.8128\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.7603\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.7236\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6777\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.6508\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 0.6123\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.5665\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.5423\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.5239\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.4913\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.4685\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.4435\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.4187\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.3999\n"
          ]
        }
      ],
      "source": [
        "#Entrenamos el modelo\n",
        "EPOCHS=50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UwLoIf-eJNDH"
      },
      "outputs": [],
      "source": [
        "model.save(\"model_paquita_100_2024.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Mk5PTDmwAqsJ"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras import losses # Import the losses module\n",
        "\n",
        "# Assuming your original loss function was, for example, binary_crossentropy\n",
        "loaded_model = load_model(\"model_paquita_100_2024.keras\",\n",
        "                          custom_objects={'loss': losses.sparse_categorical_crossentropy})\n",
        "# or if it was a custom loss function\n",
        "# loaded_model = load_model(\"model_paquita_100_2024.keras\", custom_objects={'loss': my_custom_loss_function})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3OOgx6ipdGl"
      },
      "source": [
        "**Generación de texto del modelo RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nGlNTy7xDCw5"
      },
      "outputs": [],
      "source": [
        "#Ya que tenemos entrenado los modelos vamos a usarlos para generar texto\n",
        "#Vamos a reconstruir manualmente los modelos para modifical el batch y su peso para poner el último\n",
        "model = build_model(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
        "# Build the model before loading weights\n",
        "# This creates the necessary layer variables to which weights can be assigned\n",
        "# Provide an input shape that matches the expected input of your model\n",
        "# for example:\n",
        "# input_shape = (1, sequence_length) where sequence_length is the length of your input sequences\n",
        "input_shape = (1, 100)  # Replace 100 with your actual sequence length\n",
        "model.build(input_shape=input_shape) # Or model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.load_weights(\"model_paquita_100_2024.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "q05VTagxDCzG"
      },
      "outputs": [],
      "source": [
        "#Creamos una función generar_texto que generará texto a partir de una palabra de partida\n",
        "def generate_text(model, start_string):\n",
        "\n",
        "  num_generate = 1000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "\n",
        "  temperature = 0.7\n",
        "\n",
        "#  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rac2ypCzDC1b",
        "outputId": "21fbb819-87cd-4a14-bf0b-b2e6356662d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paquita espera en el coche. Está pensativa. Llega MAGÜI con la mano y MAGÜI sonríe. PAQUITA y MAGÜI se abrazan en la puerta de un cine. Vemos que le he mirado en descocharlos. MARIONA se gonta en el coche y se aleja de ver, por un dos mánda, Puedo ser tu esclava, Puedo ser tu diva, Puedo ser tu esclava, Puedo ser tu diva, Puedo ser tu secretaria pero que no sabe ni que yo estoy allí. Detrás de todo. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA se pone el abrigo. \r\n",
            "\r\n",
            "\r\n",
            "MAGÜI le traba a la cama. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA: \r\n",
            "Ya te lo he dicho. Porque a ver si puedes arrasar al entrar se vente en cositente. Al hara del baz, se lova la mano y un cambio de la calera, que estaba a puerta de que llamas perplea de casa. PAQUITA se despierta, se levanta y quita, encanta. \r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "La puerta de PS MANAGEMENT se abre. Entra PAQUITA con gafas de sol, se encuentra de frente con MAGÜI intentando descolgar el cartel gigante de MACARENA\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Paquita espera en el coche\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnPV4P_dLFt9",
        "outputId": "b90861bf-d0ac-48ed-8924-589304779661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qué es spamena con micasona. \r\n",
            "\r\n",
            "\r\n",
            "MAGÜI coge su abrigo y entra detrás de la barra. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA (Al teléfono): \r\n",
            "¿Huanfran? Nene, que soy yo. Oye, que ya nos vamos a la boda. \r\n",
            "\r\n",
            "\r\n",
            "MAGÜI: \r\n",
            "Es que estos videobooks de parada. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA: \r\n",
            "¡Ay! Hija, ella está perdigo. \r\n",
            "\r\n",
            "\r\n",
            "MAGÜI: \r\n",
            "¿Qué tal la reconica y MAGÜI le da la récina. PAQUITA se despenta, entra de es que no me lo cuenta nada y que no esa haciendo La nieta de Mariona Felga. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA: \r\n",
            "¡Hija, estamos en comecirado estos videobooks de actores y actrices se queda sola. \r\n",
            "\r\n",
            "\r\n",
            "PAQUITA: \r\n",
            "Sí. Te dejo, expañano que te sale aquí la Estrella. A ver si está fuera la escena y BELEX la está antiendo en comecia a tu casa. ¡Hoy nos cierras la ofcina! Desflan de un lado a otro por turnos. MAGÜI se le da la rapais. MAGÜI le del puedio, andiestradera que tergan una copienta de ligar en colos. \r\n",
            "\r\n",
            "\r\n",
            "MAGÜI se queda paralizada. PAQUITA ostá fomo lo tara a MAGÜI con la mano y MAGÜI sonríe. PAQUITA y MAGÜI se abrazan en la puerta de una caleta de M\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"qué es spam\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaP2v8hkDC50"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}